{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_pause_indicator import speech, pause ; import setup; import matplotlib.pyplot as plt; import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_scale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://pyts.readthedocs.io/en/stable/auto_examples/metrics/plot_dtw.html\n",
    "from pyts.datasets import load_gunpoint; import math\n",
    "from pyts.metrics import dtw, itakura_parallelogram, sakoe_chiba_band\n",
    "from pyts.metrics.dtw import (cost_matrix, accumulated_cost_matrix, _return_path, _blurred_path_region)\n",
    "import itertools; import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original distance / alignment length\n",
    "# Maximum distance = number of points in the alignment path * largest difference between amplitude of x and y, \n",
    "# but this noramlization constant makes the new distance very small\n",
    "\n",
    "# Maximum dtw distance = number of points in the alignment path * largest difference between amplitude of x and y\n",
    "\n",
    "def normalize_distance(x, y, path, dist, method, am_scale = am_scale):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    nor_dist = dist / (am_scale * 2* len(path[0]))\n",
    "    return nor_dist    \n",
    "# unit of distance = amplitude / portion of the alignment path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all():\n",
    "    classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)\n",
    "#     itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)\n",
    "#     sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)\n",
    "#     multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyts - classic\n",
    "def classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y):\n",
    "    method = 'classic'\n",
    "    dtw_classic, path_classic = dtw(x, y, dist='absolute', method=method, return_path=True)\n",
    "    path = path_classic\n",
    "    dist = dtw_classic\n",
    "    alignment_err(x, y, path, file1, file2, seg1_1, seg1_2, seg2_1, seg2_2, time1_lst, time2_lst, xlabel, ylabel, sr, speech_x, speech_y, dist, method)\n",
    "\n",
    "#     return path, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyts itakura\n",
    "\n",
    "def itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech1, speech2):\n",
    "\n",
    "    method = 'itakura'\n",
    "    slope = 1.2\n",
    "    dtw_itakura, path_itakura = dtw(\n",
    "        x, y, dist='absolute', method='itakura',\n",
    "        options={'max_slope': slope}, return_path=True\n",
    "    )\n",
    "    parallelogram = itakura_parallelogram(n_timestamps_1, n_timestamps_2,\n",
    "                                          max_slope=slope)\n",
    "    matrix_itakura = np.zeros((n_timestamps_1 + 1, n_timestamps_2 + 1))\n",
    "    for i in range(n_timestamps_1):\n",
    "        matrix_itakura[i, np.arange(*parallelogram[:, i])] = 0.5\n",
    "    matrix_itakura[tuple(path_itakura)] = 1.\n",
    "    path = path_itakura\n",
    "    dist = dtw_itakura\n",
    "    alignment_err(x, y, path, file1, file2, seg1_1, seg1_2, seg2_1, seg2_2, time1_lst, time2_lst, xlabel, ylabel, sr, speech_x, speech_y, dist, method)    \n",
    "    \n",
    "    #return path, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyts itakura\n",
    "\n",
    "def itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech1, speech2):\n",
    "\n",
    "    method = 'itakura'\n",
    "    slope = 1.2\n",
    "    dtw_itakura, path_itakura = dtw(\n",
    "        x, y, dist='absolute', method='itakura',\n",
    "        options={'max_slope': slope}, return_path=True\n",
    "    )\n",
    "    parallelogram = itakura_parallelogram(n_timestamps_1, n_timestamps_2,\n",
    "                                          max_slope=slope)\n",
    "    matrix_itakura = np.zeros((n_timestamps_1 + 1, n_timestamps_2 + 1))\n",
    "    for i in range(n_timestamps_1):\n",
    "        matrix_itakura[i, np.arange(*parallelogram[:, i])] = 0.5\n",
    "    matrix_itakura[tuple(path_itakura)] = 1.\n",
    "    path = path_itakura\n",
    "    dist = dtw_itakura\n",
    "    alignment_err(x, y, path, file1, file2, seg1_1, seg1_2, seg2_1, seg2_2, time1_lst, time2_lst, xlabel, ylabel, sr, speech_x, speech_y, dist, method)    \n",
    "    \n",
    "    #return path, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyts sakoechiba\n",
    "\n",
    "def sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y):\n",
    "    method = \"sakoechiba\"\n",
    "    window_size = 0.1\n",
    "    dtw_sakoechiba, path_sakoechiba = dtw(\n",
    "        x, y, dist='absolute', method='sakoechiba',\n",
    "        options={'window_size': window_size}, return_path=True\n",
    "    )\n",
    "    band = sakoe_chiba_band(n_timestamps_1, n_timestamps_2,\n",
    "                            window_size=window_size)\n",
    "    matrix_sakoechiba = np.zeros((n_timestamps_1 + 1, n_timestamps_2 + 1))\n",
    "    for i in range(n_timestamps_1):\n",
    "        matrix_sakoechiba[i, np.arange(*band[:, i])] = 0.5\n",
    "    matrix_sakoechiba[tuple(path_sakoechiba)] = 1.\n",
    "\n",
    "    path = path_sakoechiba\n",
    "    dist = dtw_sakoechiba\n",
    "    alignment_err(x, y, path, file1, file2, seg1_1, seg1_2, seg2_1, seg2_2, time1_lst, time2_lst, xlabel, ylabel, sr, speech_x, speech_y, dist, method)\n",
    "    \n",
    "    # return path, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_down(num, divisor):\n",
    "    return num - (num%divisor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y):\n",
    "    method = \"multiscale\"\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "   \n",
    "    resolution, radius = 5, 2\n",
    "    dtw_multiscale, path_multiscale = dtw(\n",
    "        x, y, dist='absolute', method='multiscale',\n",
    "        options={'resolution': resolution, 'radius': radius}, return_path=True\n",
    "    )\n",
    "    \n",
    "    x = x[0: round_down(len(x), resolution)]\n",
    "    y = y[0: round_down(len(y), resolution)]\n",
    "\n",
    "    x_padded = x.reshape(-1, resolution).mean(axis=1)\n",
    "    y_padded = y.reshape(-1, resolution).mean(axis=1)\n",
    "\n",
    "    cost_mat_res = cost_matrix(x_padded, y_padded, dist='absolute', region=None)\n",
    "    acc_cost_mat_res = accumulated_cost_matrix(cost_mat_res)\n",
    "    path_res = _return_path(acc_cost_mat_res)\n",
    "\n",
    "    n_timestamps_1 = len(x)\n",
    "    n_timestamps_2 = len(y)\n",
    "    \n",
    "    multiscale_region = _blurred_path_region(\n",
    "        n_timestamps_1, n_timestamps_2, resolution, x_padded.size, y_padded.size,\n",
    "        path_res,\n",
    "        radius=radius\n",
    "    )    \n",
    "    \n",
    "    matrix_multiscale = np.zeros((n_timestamps_1 + 1, n_timestamps_2 + 1))\n",
    "    \n",
    "    for i in range(n_timestamps_1):\n",
    "        matrix_multiscale[i, np.arange(*multiscale_region[:, i])] = 0.5\n",
    "\n",
    "    path = path_multiscale\n",
    "    dist = dtw_multiscale\n",
    "    \n",
    "    alignment_err(x, y, path, file1, file2, seg1_1, seg1_2, seg2_1, seg2_2, time1_lst, time2_lst, xlabel, ylabel, sr, speech_x, speech_y, dist, method)\n",
    "     \n",
    "    # return path, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_xy(smooth_s, smooth_r, time1, seg1_1, seg1_2, time2, seg2_1, seg2_2):\n",
    "    \n",
    "    query = smooth_s\n",
    "    ref = smooth_r\n",
    "    x = (time1 - seg1_1)/(seg1_2 - seg1_1) * len(query)\n",
    "    y = (time2 - seg2_1)/(seg2_2 - seg2_1) * len(ref)\n",
    "    return x, y\n",
    "\n",
    "# deviation function\n",
    "def deviation(rho, theta):\n",
    "    dev = 0\n",
    "    if rho >= theta and rho <= math.pi/2:\n",
    "        dev = (rho-theta)/(math.pi/2-theta)\n",
    "    else:\n",
    "        dev = (theta - rho)/theta\n",
    "    return dev\n",
    "\n",
    "def stretch(path, speech_1, speech_2):\n",
    "    len_x = max(path[0])\n",
    "    len_y = max(path[1])\n",
    "    xs = path[0]\n",
    "    ys = path[1]\n",
    "    theta = math.atan(len_y/len_x)    \n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    \n",
    "    stretch_speech = 0\n",
    "    stretch_pause = 0\n",
    "    stretch_others = 0\n",
    "    overall_stretch = 0\n",
    "\n",
    "    # For 1 point in the warping path x, y\n",
    "    # xs[i] = index of the point in the original query that dtw uses to align x\n",
    "    # ys[i] = index of the point in the original reference query that dtw uses to align y                  \n",
    "    \n",
    "    # length of path = len(path[0]) = len(path[1])\n",
    "    for i in range(len(path[0])-1):\n",
    "        if xs[i+1]-xs[i] == 0:\n",
    "            rho_i = math.pi/2\n",
    "        else:\n",
    "            rho_i = math.atan((ys[i+1]-ys[i]) / (xs[i+1]-xs[i]))\n",
    "\n",
    "        dev_rho_i = deviation(rho_i, theta)\n",
    "        numerator = dev_rho_i*math.sqrt((xs[i+1]-xs[i])**2 + (ys[i+1]-ys[i])**2)\n",
    "        denominator = denominator + math.sqrt((xs[i+1]-xs[i])**2 + (ys[i+1]-ys[i])**2)\n",
    "\n",
    "        sp1 = speech_1[xs[i]]\n",
    "        sp2 = speech_2[ys[i]]\n",
    "        \n",
    "        if sp1 == sp2 == 1: # Add the deviation to either speech, pause, or not aligned\n",
    "            stretch_speech = stretch_speech + numerator\n",
    "        elif sp1 == sp2 == 0:\n",
    "            stretch_pause = stretch_pause + numerator\n",
    "        else:\n",
    "            stretch_others = stretch_others+ numerator\n",
    "            \n",
    "    overall_stretch = (stretch_speech + stretch_pause + stretch_others)/denominator\n",
    "    \n",
    "    return stretch_speech/denominator, stretch_pause/denominator, stretch_others/denominator, overall_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment_err(x, y, path, file1, file2, seg1_1, seg1_2, seg2_1, seg2_2, time1_lst, time2_lst, xlabel, ylabel, sr, speech1, speech2, dist, method):\n",
    "    nor_dist = normalize_distance(x, y, path, dist, method)\n",
    "    colors = ['red', 'g', 'b', 'm', 'brown', '#d89743', 'grey', 'c', 'orange', 'g', 'b', 'm', 'red']\n",
    "    err = []\n",
    "    for i in range(len(time1_lst)):\n",
    "        x_axis, y_axis = get_word_xy(x, y, time1_lst[i], seg1_1, seg1_2, time2_lst[i], seg2_1, seg2_2)\n",
    "        \n",
    "        plt.scatter(x_axis, y_axis, color = colors[i], marker = \"X\", edgecolor = 'black', s = 100)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        \n",
    "        x_val = list(itertools.chain(*np.where(np.abs(path[0] - x_axis) < 1)))[0]\n",
    "        y_val = list(itertools.chain(*np.where(np.abs(path[1] - y_axis) < 1)))[0]\n",
    "\n",
    "        warp_y = path[1][x_val]\n",
    "        warp_x = path[0][y_val]\n",
    "        \n",
    "        e = (np.abs(warp_x - x_axis) + np.abs(warp_y - y_axis))/sr\n",
    "        err.append(e)    # unit = second\n",
    "        \n",
    "    median = statistics.median(err)\n",
    "    err_sum = sum(err)\n",
    "    \n",
    "    plt.title('dtw %s distance: %.10f' %(method, nor_dist));    \n",
    "    plt.plot(path[0], path[1]);    \n",
    "    \n",
    "    text1 = 'Avg err (s): %.3f. \\nMedian err (s): %.3f' %(err_sum/len(time1_lst), median)\n",
    "    text2 = '\\nStretch speech: %.3f \\nStretch pause: %.3f. \\nStretch unaligned: %.3f. \\nStretch overall: %.3f.' %stretch(path, speech1, speech2)    \n",
    "\n",
    "    # print text\n",
    "    plt.text(max(path[0]) + 2000, 0, text1+text2, fontsize=14)\n",
    "    plt.grid(True)\n",
    "    plt.subplots_adjust(right = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr):\n",
    "    from scipy.io import wavfile \n",
    "    capstone_dir = \"/Users/ninismacbook/other_docs/Y4S1/capstone\" \n",
    "    \n",
    "    file1_path = capstone_dir + \"/py_converted/\" + file1 ; file2_path = capstone_dir + \"/py_converted/\" + file2\n",
    "    \n",
    "    samplerate, query = wavfile.read(file1_path) ; samplerate, ref = wavfile.read(file2_path)\n",
    "    new_sr = samplerate/sr\n",
    "    # If input sr = 4410, then new_sr = 44100/4410 = 10 (samplerate from py_converted is always 44100)\n",
    "    \n",
    "    query_sample = query[0: int(samplerate*seg1_2)] # Original query based on input timestamps\n",
    "    ref_sample = ref[0: int(samplerate*seg2_2)] # From the beginning until seg 2\n",
    "    \n",
    "    frame_per_window = samplerate * window_len/1000 # Smoothen the two arrays\n",
    "\n",
    "    smooth_query_sample = [] # Store arrays after downsampling \n",
    "    smooth_ref_sample = []\n",
    "    \n",
    "    smooth_s = [] # Smoothened sample\n",
    "    smooth_r = [] # smoothened ref\n",
    "    \n",
    "    query_s = []\n",
    "    ref_s = []\n",
    "    \n",
    "    # Rolling average on query_sample\n",
    "    for i in range(len(query_sample)):\n",
    "        if i < frame_per_window/2:\n",
    "            i1 = 0 ; i2 = i + int(frame_per_window/2)            \n",
    "        elif i > (len(query_sample) - frame_per_window/2):\n",
    "            i1 = i - frame_per_window/2 ; i2 = len(query_sample)\n",
    "        else:\n",
    "            i1 = i-frame_per_window/2 ; i2 = i+frame_per_window/2\n",
    "        \n",
    "        smooth_s.append(np.mean(np.abs(query_sample[int(i1) : int(i2)])))\n",
    "    \n",
    "    for i in range(len(ref_sample)):\n",
    "        if i < frame_per_window/2:\n",
    "            i1 = 0 ; i2 = i + int(frame_per_window/2)            \n",
    "        elif i > (len(ref_sample) - frame_per_window/2):\n",
    "            i1 = i - frame_per_window/2 ; i2 = len(ref_sample)\n",
    "        else:\n",
    "            i1 = i-frame_per_window/2 ; i2 = i+frame_per_window/2\n",
    "        \n",
    "        smooth_r.append(np.mean(np.abs(ref_sample[int(i1) : int(i2)])))\n",
    "    \n",
    "    smooth_s = smooth_s[int(samplerate*seg1_1): int(samplerate*seg1_2)]\n",
    "    smooth_r = smooth_r[int(samplerate*seg2_1): int(samplerate*seg2_2)]\n",
    "    \n",
    "    longer_query_len = len(smooth_s)\n",
    "    a = len(smooth_r) \n",
    "    if a > longer_query_len:\n",
    "        longer_query_len = a        \n",
    "    \n",
    "    query_sample = query[int(samplerate*seg1_1): int(samplerate*seg1_2)] # Original query based on input timestamps\n",
    "    ref_sample = ref[int(samplerate*seg2_1): int(samplerate*seg2_2)]        \n",
    "        \n",
    "    max_m1 = np.abs(max(query))\n",
    "    max_m2 = np.abs(max(ref))\n",
    "    \n",
    "    # Downsampling\n",
    "    for i in range(int(longer_query_len // new_sr)):\n",
    "        \n",
    "        # Only append when the index is within the length of query_sample and ref_sample\n",
    "        if int(i*new_sr) < len(smooth_s):\n",
    "            smooth_query_sample.append(smooth_s[int(i*new_sr)]/max_m1)\n",
    "            \n",
    "        if int(i*new_sr) < len(smooth_r):\n",
    "            smooth_ref_sample.append(smooth_r[int(i*new_sr)]/max_m2) \n",
    "            \n",
    "#     print('smooth query sample: ', len(smooth_query_sample), 'smooth ref sample: ', len(smooth_ref_sample))\n",
    "#     print('smooth_s', len(smooth_s))\n",
    "\n",
    "    # Get speech indicator for the two samples\n",
    "    query_s = speech(smooth_s, query, seg1_1, seg1_2, samplerate, frame_per_window)\n",
    "    ref_s = speech(smooth_r, ref, seg2_1, seg2_2, samplerate, frame_per_window)      \n",
    "    \n",
    "    # Plot original amplitude graph for first sample\n",
    "    plot_q = query[int(samplerate*seg1_1): int(samplerate*seg1_2)]\n",
    "    time1 = np.linspace(seg1_1, seg1_2, num = len(plot_q))    \n",
    "    plt.figure(figsize=(18.5, 2))    \n",
    "    plt.plot(time1, plot_q)\n",
    "    \n",
    "    # Plot the rolling average and speech indicator function for the first sample\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1); fig.set_size_inches(18.5, 2.5)\n",
    "    length = len(smooth_s) / samplerate\n",
    "    time1 = np.linspace(seg1_1, seg1_2, num = len(smooth_s))           \n",
    "    ax1.plot(time1, smooth_s, color = '#A4A4A4')\n",
    "    ax2.plot(time1, query_s, color = '#A4A4A4');\n",
    "\n",
    "    # Plot original amplitude graph for second sample\n",
    "    plot_r = ref[int(samplerate*seg2_1): int(samplerate*seg2_2)]\n",
    "    time2 = np.linspace(seg2_1, seg2_2, num = len(plot_r))\n",
    "    plt.figure(figsize=(18.5, 2))\n",
    "    plt.plot(time2, plot_r)\n",
    "    \n",
    "    # Plot the rolling average and speech indicator function for the second sample    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1); fig.set_size_inches(18.5, 2.5)\n",
    "    time2 = np.linspace(seg2_1, seg2_2, num = len(smooth_r))\n",
    "    ax1.plot(time2, smooth_r, color = '#A4A4A4')\n",
    "    ax2.plot(time2, ref_s, color = '#A4A4A4');       \n",
    "    \n",
    "    return query_sample, ref_sample, sr, smooth_query_sample, smooth_ref_sample, query_s, ref_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech(smooth_query, original_query, seg1_1, seg1_2, samplerate, frame_per_window):\n",
    "    \n",
    "    # Take the amplitudes in the 30 ms as the window. Find upper and lower bound\n",
    "    # Avoid the immediate ms in the beginning of the query because some devices have start sound\n",
    "    \n",
    "    abs_q = np.abs(original_query[int(samplerate*0.5): int(samplerate*0.5 + frame_per_window)])\n",
    "    \n",
    "    smooth_s = []\n",
    "    abs_q_len = len(abs_q)\n",
    "#     print(frame_per_window)\n",
    "#     print(abs_q_len)\n",
    "    \n",
    "    # Rolling average for the first half second: for the upper and lower bound filter\n",
    "    for i in range(int(abs_q_len)):\n",
    "        if i < frame_per_window/2:\n",
    "            i1 = 0 ; i2 = i + int(frame_per_window/2)            \n",
    "        elif i > (abs_q_len - frame_per_window/2):\n",
    "            i1 = i - frame_per_window/2 ; i2 = abs_q_len\n",
    "        else:\n",
    "            i1 = i-frame_per_window/2 ; i2 = i+frame_per_window/2\n",
    "\n",
    "        smooth_s.append(np.mean(abs_q[int(i1) : int(i2)]))\n",
    "    \n",
    "    # Upper and lower bound of the filter: absolute value of amplitude. Upper and lower refers to the silent amplitude\n",
    "    \n",
    "    upper = np.max(smooth_s)\n",
    "    lower = np.min(smooth_s)\n",
    "    \n",
    "#     print(upper, lower)\n",
    "#     print(np.max(smooth_query))\n",
    "#     print(np.min(smooth_query))\n",
    "    \n",
    "    result = []                \n",
    "    for i in range(len(smooth_query)):\n",
    "        if np.abs(smooth_query[i]) > upper :\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bamboo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 40 # Unit: ms\n",
    "sr = 8000\n",
    "play_sr = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 3.3, 3.9\n",
    "file2, seg2_1, seg2_2 = \"test2.wav\", 0, 2\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "xlabel = file1 ;  ylabel = file2\n",
    "time1_lst = [3.46]\n",
    "time2_lst = [1.43]\n",
    "\n",
    "setup.play_samples(play_x, play_y, play_sr)\n",
    "plot_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B B Bamboo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 3.3, 3.9\n",
    "file2, seg2_1, seg2_2 = \"repeat-syllable01.wav\", 1.5, 3.5\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "xlabel = file1 ;  ylabel = file2\n",
    "time1_lst = [3.46]\n",
    "time2_lst = [2.88]\n",
    "\n",
    "# setup.play_samples(play_x, play_y, play_sr)\n",
    "plot_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - Bamboo walls vs Bamboo + pause + walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"test2.wav\", 0, 3\n",
    "file2, seg2_1, seg2_2 = \"test1.wav\", 1, 6\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "xlabel = file1 ;  ylabel = file2\n",
    "time1_lst = [1.43, 2.01]\n",
    "time2_lst = [1.37, 4.56]\n",
    "\n",
    "setup.play_samples(play_x, play_y, play_sr)\n",
    "plot_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TORGO: Except in the winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 8000 ; play_sr = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"torgo-healthy.wav\", 2, 3.7\n",
    "file2, seg2_1, seg2_2 = \"torgo-patient.wav\", 2.5, 5\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "\n",
    "xlabel = \"Except in the winter - healthy\" ;  ylabel = \"Except in the winter - patient\"\n",
    "time1_lst = [2.34, 2.86, 3.03, 3.26] ; time2_lst = [2.8, 3.86, 4.03, 4.20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(len(x), len(y), len(speech_x), len(speech_y))\n",
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torgo: when the ooze or snow or ice prevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"torgo-healthy.wav\", 3.7, 6.50\n",
    "file2, seg2_1, seg2_2 = \"torgo-patient.wav\", 5, 11.38\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [3.94, 4.03, 4.38, 4.8, 5.1, 5.54, 5.73, 6.18] ;\n",
    "time2_lst = [7.07, 7.26, 7.78, 8.21, 8.53, 9.57, 9.9, 10.76]\n",
    "xlabel = \"Healthy: when the ooze or snow or ice presents\" ;  ylabel = \"patient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bamboo - perfect alignment - Normal v.s. Normal 01 vs. 01_1 Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 3.4, 6\n",
    "file2, seg2_1, seg2_2 = \"01_1.wav\", 2, 5\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "xlabel = \"Bamboo walls are getting to be very popular - Normal 1\" ;  ylabel = \"Normal 01_1\"\n",
    "time1_lst = [3.46, 3.88, 4.16, 4.42, 4.77, 4.91, 5.21, 5.47] ;\n",
    "time2_lst = [2.33, 2.63, 2.87, 3.12, 3.4, 3.57, 3.74, 4.06]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bamboo - perfect alignment - Normal v.s. Normal 01 vs. 01_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 3.4, 6\n",
    "file2, seg2_1, seg2_2 = \"01_2.wav\", 2, 5\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "\n",
    "xlabel = \"Bamboo walls are getting to be very popular - Normal 01\" ;  ylabel = \"Normal 01_2\"\n",
    "time1_lst = [3.46, 3.88, 4.16, 4.42, 4.77, 4.91, 5.21, 5.47] ;\n",
    "time2_lst = [2.28, 2.72, 2.93, 3.18, 3.51, 3.66, 3.84, 4.11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bamboo - perfect alignment - Normal v.s. Normal 01 vs. 01_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 3.4, 6\n",
    "file2, seg2_1, seg2_2 = \"01_3.wav\", 2, 4.7\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "\n",
    "xlabel = \"Bamboo walls are getting to be very popular - Normal 1\" ;  ylabel = \"Normal 01_3\"\n",
    "time1_lst = [3.46, 3.88, 4.16, 4.42, 4.77, 4.91, 5.21, 5.47] ;\n",
    "time2_lst = [2.06, 2.45, 2.7, 2.94, 3.23, 3.41, 3.62, 3.98];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bamboo - perfect alignment - Normal v.s. Normal 01_2 vs. 01_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01_2.wav\", 2, 4.15\n",
    "file2, seg2_1, seg2_2 = \"01_3.wav\", 2, 4\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "\n",
    "xlabel = \"Bamboo walls are getting to be very popular - Normal 01_2\" ;  ylabel = \"Normal 01_3\"\n",
    "\n",
    "time1_lst = [2.28, 2.72, 2.93, 3.18, 3.51, 3.66, 3.84, 4.11]\n",
    "time2_lst = [2.06, 2.45, 2.7, 2.94, 3.23, 3.41, 3.62, 3.98];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bamboo - perfect alignment - Normal v.s. Normal 01_1 vs. 01_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01_1.wav\", 2, 4.1\n",
    "file2, seg2_1, seg2_2 = \"01_2.wav\", 2, 4.15\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [2.33, 2.63, 2.87, 3.12, 3.4, 3.57, 3.74, 4.06]\n",
    "time2_lst = [2.28, 2.72, 2.93, 3.18, 3.51, 3.66, 3.84, 4.11]\n",
    "\n",
    "xlabel = \"Bamboo walls are getting to be very popular - Normal 01_1\" ;  ylabel = \"Normal 01_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bamboo - perfect alignment - Normal v.s. Normal 01_1 vs. 01_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01_1.wav\", 2, 4.1\n",
    "file2, seg2_1, seg2_2 = \"01_3.wav\", 2, 4\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [2.33, 2.63, 2.87, 3.12, 3.4, 3.57, 3.74, 4.06]\n",
    "time2_lst = [2.06, 2.45, 2.7, 2.94, 3.23, 3.41, 3.62, 3.98];\n",
    "xlabel = \"Bamboo walls are getting to be very popular - Normal 01_1\" ;  ylabel = \"Normal 01_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bamboo - normal vs. slightly slow: 01 vs 02: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 2, 6\n",
    "file2, seg2_1, seg2_2 = \"02.wav\", 1.7, 5\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [3.46, 3.88, 4.16, 4.42, 4.77, 4.91, 5.21, 5.47] ;\n",
    "time2_lst = [1.74, 2.42, 2.92, 3.52, 3.75, 3.88, 4.29, 4.48]\n",
    "xlabel = \"Bamboo walls are getting to be very popular - Normal 01\" ;  ylabel = \"Normal 02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bamboo - normal vs. short pauses: 01 vs 05: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 2, 6\n",
    "file2, seg2_1, seg2_2 = \"05.wav\", 1.4, 6\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [3.46, 3.88, 4.16, 4.42, 4.77, 4.91, 5.21, 5.47] \n",
    "time2_lst = [1.45, 1.83, 2.92, 3.17, 3.5, 3.64, 4.78, 5.09]\n",
    "xlabel = \"Bamboo walls are getting to be very popular - 01\" ;  ylabel = \"05\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bamboo - normal vs. repeat part of word + pauses: 01 vs pause_m01: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 2, 6\n",
    "file2, seg2_1, seg2_2 = \"pause_m01.wav\", 1.5, 13\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [3.46, 3.88, 4.16, 4.42, 4.77, 4.91, 5.21, 5.47] \n",
    "time2_lst = [4.52, 5.11, 9.18, 9.45, 9.82, 9.95, 11.06, 11.30]\n",
    "\n",
    "xlabel = \"Bamboo walls are getting to be very popular - 01\" ;  ylabel = file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal vs. slightly faster: 01 vs 01_1: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 2, 6\n",
    "file2, seg2_1, seg2_2 = \"01_1.wav\", 1.5, 5\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [3.46, 3.88, 4.16, 4.42, 4.77, 4.91, 5.21, 5.47] \n",
    "time2_lst = [2.33, 2.63, 2.87, 3.12, 3.40, 3.57, 3.74, 4.06]\n",
    "\n",
    "xlabel = \"Bamboo walls are getting to be very popular - 01\" ;  ylabel = \"pause_m01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal vs Stutter 01 vs repeat-syllable01: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 2, 6\n",
    "file2, seg2_1, seg2_2 = \"repeat-syllable01.wav\", 1, 7\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [3.46, 3.88, 4.16, 4.42, 4.77, 4.91, 5.21, 5.47] \n",
    "time2_lst = [2.97, 3.6, 4.07, 4.30, 4.58, 4.75, 4.98, 6.1]\n",
    "\n",
    "xlabel = \"Bamboo walls are getting to be very popular - 01\" ;  ylabel = file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal vs Stutter 01_1 vs repeat-syllable01: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01_1.wav\", 2, 4.5\n",
    "file2, seg2_1, seg2_2 = \"repeat-syllable01.wav\", 1, 7\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [2.33, 2.63, 2.87, 3.12, 3.40, 3.57, 3.74, 4.06]\n",
    "time2_lst = [2.97, 3.6, 4.07, 4.30, 4.58, 4.75, 4.98, 6.1]\n",
    "\n",
    "xlabel = \"Bamboo walls are getting to be very popular - 01\" ;  ylabel = file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal vs Stutter 01_2 vs repeat-syllable01: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01_2.wav\", 2, 4.5\n",
    "file2, seg2_1, seg2_2 = \"repeat-syllable01.wav\", 1, 7\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [2.28, 2.72, 2.93, 3.18, 3.51, 3.66, 3.84, 4.11]\n",
    "time2_lst = [2.97, 3.6, 4.07, 4.30, 4.58, 4.75, 4.98, 6.1]\n",
    "\n",
    "xlabel = \"Bamboo walls are getting to be very popular - 01\" ;  ylabel = file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal vs Slower: 01 vs 02_1: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 2, 6\n",
    "file2, seg2_1, seg2_2 = \"02_1.wav\", 2.5, 7\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [3.46, 3.88, 4.16, 4.42, 4.77, 4.91, 5.21, 5.47] \n",
    "time2_lst = [3.23, 3.90, 4.61, 4.97, 5.27, 5.45, 6.19, 6.57]\n",
    "xlabel = \"Bamboo walls are getting to be very popular - 01\" ;  ylabel = file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal vs Slower: 01_1 vs 02_1: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01_1.wav\", 2, 4.1\n",
    "file2, seg2_1, seg2_2 = \"02_1.wav\", 2.5, 7\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [2.33, 2.63, 2.87, 3.12, 3.40, 3.57, 3.74, 4.06]\n",
    "time2_lst = [3.23, 3.90, 4.61, 4.97, 5.27, 5.45, 6.19, 6.57]\n",
    "xlabel = \"Bamboo walls are getting to be very popular - 01\" ;  ylabel = file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal vs Slower: 01_2 vs 02_1: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01_2.wav\", 2, 5\n",
    "file2, seg2_1, seg2_2 = \"02_1.wav\", 2.5, 7\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [2.28, 2.72, 2.93, 3.18, 3.51, 3.66, 3.84, 4.11]\n",
    "time2_lst = [3.23, 3.90, 4.61, 4.97, 5.27, 5.45, 6.19, 6.57]\n",
    "xlabel = \"Bamboo walls are getting to be very popular - 01\" ;  ylabel = file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal vs Slower: 01_3 vs 02_1: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01_3.wav\", 2, 4\n",
    "file2, seg2_1, seg2_2 = \"02_1.wav\", 2.5, 7\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [2.06, 2.45, 2.7, 2.94, 3.23, 3.41, 3.62, 3.98];\n",
    "time2_lst = [3.23, 3.90, 4.61, 4.97, 5.27, 5.45, 6.19, 6.57]\n",
    "xlabel = \"Bamboo walls are getting to be very popular - 01\" ;  ylabel = file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal vs Slower: 01 vs long_w01: Bamboo walls are getting to be very popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, seg1_1, seg1_2 = \"01.wav\", 2, 6\n",
    "file2, seg2_1, seg2_2 = \"long_w01.wav\", 1.5, 21\n",
    "\n",
    "play_x, play_y, sr, x, y, speech_x, speech_y = make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2, sr)\n",
    "n_timestamps_1, n_timestamps_2 = len(x), len(y)\n",
    "time1_lst = [3.46, 3.88, 4.16, 4.42, 4.77, 4.91, 5.21, 5.47] ;\n",
    "time2_lst = [1.61, 6.12, 8.73, 11.11, 13.33, 15.80, 18.30, 20.72]\n",
    "\n",
    "\n",
    "xlabel = \"Bamboo walls are getting to be very popular - 01\" ;  ylabel = file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.play_samples(play_x, play_y, play_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classic(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itakura(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sakoechiba(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiscale(x, y, xlabel, ylabel, time1_lst, time2_lst, sr, speech_x, speech_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
