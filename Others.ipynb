{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dtw import *\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "import sounddevice as sd\n",
    "from os.path import dirname, join as pjoin\n",
    "from scipy.io import wavfile\n",
    "import scipy.io;\n",
    "import os\n",
    "import glob\n",
    "import webrtcvad\n",
    "import statistics\n",
    "\n",
    "import collections\n",
    "import contextlib\n",
    "import sys\n",
    "import wave\n",
    "\n",
    "vad = webrtcvad.Vad()\n",
    "\n",
    "import contextlib\n",
    "\n",
    "\n",
    "capstone_dir = \"/Users/ninismacbook/other docs/Y4S1/capstone\"\n",
    "\n",
    "query_sample = []\n",
    "ref_sample = []\n",
    "blocksize = 18000\n",
    "\n",
    "def make_samples(file1, seg1_1, seg1_2, file2, seg2_1, seg2_2):\n",
    "    \n",
    "    file1_path = capstone_dir + \"/downsampled/\" + file1\n",
    "    file2_path = capstone_dir + \"/downsampled/\" + file2\n",
    "\n",
    "    samplerate, query = wavfile.read(file1_path)\n",
    "    samplerate, ref = wavfile.read(file2_path)\n",
    "\n",
    "    query_sample = query[int(samplerate*seg1_1): int(samplerate*seg1_2)]\n",
    "    ref_sample = ref[int(samplerate*seg2_1): int(samplerate*seg2_2)]\n",
    "    \n",
    "    return query_sample, ref_sample, samplerate\n",
    "\n",
    "def play_samples():\n",
    "    sd.play(query_sample, samplerate = samplerate, blocksize=blocksize, blocking=True)\n",
    "    sd.play(ref_sample, samplerate = samplerate, blocksize=blocksize, blocking=True);\n",
    "    \n",
    "def plot_alignment(alignment):\n",
    "    alignment.plot(type=\"threeway\"); \n",
    "    print('DTW distance: ', alignment.distance);\n",
    "    print('How much stretching: ', how_much_stretch(alignment))\n",
    "    \n",
    "def how_much_stretch(alignment):\n",
    "    align_len = len(alignment.index1)\n",
    "    xs = alignment.index1\n",
    "    ys = alignment.index2\n",
    "    abs_term = 0\n",
    "    \n",
    "    for i in range(align_len):\n",
    "        if i == 0:\n",
    "            pass\n",
    "        if i == align_len-1:\n",
    "            pass\n",
    "        else:\n",
    "            # alignment.M = len of Y axis, alignment.N = len of X axis\n",
    "            abs_term = abs_term + np.abs((ys[i] - ys[i-1])/(xs[i]-xs[i-1]) - (alignment.N + 1)/(alignment.M+1))\n",
    "        \n",
    "        return (1/align_len)*abs_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice activity detection in python (webrtcsav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wave(path):\n",
    "    \"\"\"Reads a .wav file.\n",
    "    Takes the path, and returns (PCM audio data, sample rate).\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1\n",
    "        sample_width = wf.getsampwidth()\n",
    "        assert sample_width == 2\n",
    "        sample_rate = wf.getframerate()\n",
    "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
    "        pcm_data = wf.readframes(wf.getnframes())\n",
    "        return pcm_data, sample_rate\n",
    "        \n",
    "\n",
    "# Convert all records into true or false based on whether there is voice activity or not\n",
    "def speak_pause_rate(audio_path, frame_len):\n",
    "    \n",
    "    speech = []\n",
    "    vad.set_mode(1)\n",
    "\n",
    "    # 1 pair of \\x00\\x00 corresponds to 1 frame\n",
    "    data, samplerate = read_wave(capstone_dir + audio_path)\n",
    "\n",
    "    speech_segments = [data[i:i+frame_len] for i in range(0, len(data)-frame_len, frame_len)]\n",
    "    \n",
    "    print(speech_segments[0])\n",
    "    for i in speech_segments:\n",
    "        speech.append(vad.is_speech(i, sample_rate = samplerate))\n",
    "    print(speech[0])\n",
    "    \n",
    "    segment0 = b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
    "#     print('equal ', segment0 == speech[0])\n",
    "    \n",
    "    pause = [not elem for elem in speech]\n",
    "    return (speech.count(True)/len(speech)), (pause.count(True)/len(speech))\n",
    "\n",
    "# Does not count the first (before speaker starts speaking) and last pause (after speaker finishes speaking)\n",
    "def number_of_pauses(audio_path, frame_len):\n",
    "    speech = []\n",
    "    \n",
    "    vad.set_mode(1)\n",
    "    data, samplerate = read_wave(capstone_dir + '/downsampled/01.wav')\n",
    "    speech_segments = [data[i:i+frame_len] for i in range(0, len(data)-frame_len, frame_len)]\n",
    "    \n",
    "    for i in speech_segments:\n",
    "        speech.append(vad.is_speech(i, sample_rate = samplerate))\n",
    "    \n",
    "#     print(speech)\n",
    "    for i in range(len(speech)):\n",
    "        # Find the first True i.e. find the time when speaker starts speaking \n",
    "        if(speech[i]==True):\n",
    "            return('Index of the speech segment when speaker starts speaking', i, speech[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
      "False\n",
      "(0.8663543675943787, 0.13364563240562138)\n",
      "('Index of the speech segment when speaker starts speaking', 0, True)\n"
     ]
    }
   ],
   "source": [
    "print(speak_pause_rate('/downsampled/01.wav', frame_len = 160))        \n",
    "print(number_of_pauses('/downsampled/01.wav', frame_len = 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
      "Contains speech:  True\n"
     ]
    }
   ],
   "source": [
    "# Run the VAD on 10 ms of silence. The result should be False.\n",
    "vad.set_mode(1)\n",
    "sample_rate = 8000\n",
    "frame_duration = 10  # ms\n",
    "frame = b'\\x00\\x00' * int(sample_rate * frame_duration / 1000)\n",
    "print(frame)\n",
    "print('Contains speech: ' , vad.is_speech(frame, sample_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
